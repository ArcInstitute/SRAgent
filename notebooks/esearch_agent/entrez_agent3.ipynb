{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "* Create a general supervisor-working agent that can use entrez tools to explore an Entrez record\n",
    "* Better dealing with large number of Entrez records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import xmltodict\n",
    "from enum import Enum\n",
    "from pprint import pprint\n",
    "from typing import Annotated, List, Dict, Tuple, Optional, Union, Any\n",
    "import xml.etree.ElementTree as ET\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "from Bio import Entrez\n",
    "import pandas as pd\n",
    "import threading\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "load_dotenv()\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "os.environ[\"DEBUG_MODE\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG_MODE is enabled.\n"
     ]
    }
   ],
   "source": [
    "# checks\n",
    "if os.getenv(\"DEBUG_MODE\") == \"TRUE\":\n",
    "    print(\"DEBUG_MODE is enabled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Entrez\n",
    "Entrez.email = \"nick.youngblut@arcinstitute.org\"\n",
    "Entrez.api_key = os.getenv(\"NCBI_API_KEY\")\n",
    "# Set to 10 for API key users\n",
    "request_limiter = threading.Semaphore(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_ids(ids, batch_size):\n",
    "    \"\"\"\n",
    "    Batch a list of IDs into smaller lists of a given size.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(ids), batch_size):\n",
    "        yield ids[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_values(record, max_length):\n",
    "    # truncate long values in the record\n",
    "    root = ET.fromstring(record)\n",
    "    for item in root.findall(\".//Item\"):\n",
    "        if item.text and len(item.text) > max_length:\n",
    "            item.text = item.text[:max_length] + \"...[truncated]\"\n",
    "    # convert back to string\n",
    "    return ET.tostring(root, encoding=\"unicode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### esearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool \n",
    "def esearch(\n",
    "    esearch_query: Annotated[str, \"Entrez query string.\"],\n",
    "    database: Annotated[str, \"Database name (e.g., sra, gds, or pubmed)\"],\n",
    "    )-> Annotated[List[str], \"Entrez IDs of database records\"]:\n",
    "    \"\"\"\n",
    "    Run an Entrez search query and return the Entrez IDs of the results.\n",
    "    Example query for single cell RNA-seq:\n",
    "        `(\"single cell\"[Title] OR \"single-cell\"[Title] OR \"scRNA-seq\"[Title])`\n",
    "    Example query for an ENA accession number (database = sra):\n",
    "        `ERX13336121`\n",
    "    Example query for a GEO accession number (database = gds):\n",
    "        `GSE51372`\n",
    "    \"\"\"\n",
    "    # debug model\n",
    "    if os.getenv(\"DEBUG_MODE\") == \"TRUE\":\n",
    "        max_records = 2 \n",
    "\n",
    "    # query\n",
    "    records = []\n",
    "    retstart = 0\n",
    "    retmax = 50\n",
    "    while True:\n",
    "        try:\n",
    "            search_handle = Entrez.esearch(\n",
    "                db=database, \n",
    "                term=esearch_query, \n",
    "                retstart=retstart, \n",
    "                retmax=retmax\n",
    "            )\n",
    "            search_results = Entrez.read(search_handle)\n",
    "            search_handle.close()\n",
    "            # delete unneeded keys\n",
    "            to_rm = [\"RetMax\", \"RetStart\"]\n",
    "            for key in to_rm:\n",
    "                if key in search_results.keys():\n",
    "                    del search_results[key]\n",
    "            # add to records\n",
    "            records.append(str(search_results))\n",
    "            # update retstart\n",
    "            retstart += retmax\n",
    "            time.sleep(0.33)\n",
    "            if max_records and len(records) >= max_records:\n",
    "                break\n",
    "            if retstart >= int(search_results['Count']):\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching {database} with query: {esearch_query}: {str(e)}\")\n",
    "            break \n",
    "        \n",
    "    # return records\n",
    "    if len(records) == 0:\n",
    "        return(f\"No records found for query: {esearch_query}\")\n",
    "    if os.getenv(\"DEBUG_MODE\") == \"TRUE\":\n",
    "        records = records[:max_records]  # debug\n",
    "    return records\n",
    "\n",
    "# esearch.invoke({\"esearch_query\" : \"GSE51372\", \"database\" : \"sra\"})\n",
    "# esearch.invoke({\"esearch_query\" : \"GSE121737\", \"database\" : \"gds\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### efetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool \n",
    "def efetch(\n",
    "    entrez_ids: Annotated[List[str], \"List of Entrez IDs\"],\n",
    "    database: Annotated[str, \"Database name (e.g., sra, gds, or pubmed)\"],\n",
    ") -> Annotated[str, \"eFetch results in XML format\"]:\n",
    "    \"\"\"\n",
    "    Run an Entrez efetch query on Entrez IDs to obtain metadata for the records.\n",
    "    Useful for obtaining metadata for specific records.\n",
    "    \"\"\"\n",
    "    batch_size = 200  # Maximum number of IDs per request as per NCBI guidelines\n",
    "    records = []\n",
    "\n",
    "    for id_batch in batch_ids(entrez_ids, batch_size):\n",
    "        time.sleep(0.34)  # Respect the rate limit of 3 requests per second\n",
    "        id_str = \",\".join(id_batch)\n",
    "        try:\n",
    "            # Fetch the records for the current batch of IDs\n",
    "            handle = Entrez.efetch(db=database, id=id_str, retmode=\"xml\")\n",
    "            batch_record = handle.read()\n",
    "            handle.close()\n",
    "        except Entrez.Parser.ValidationError:\n",
    "            print(f\"Failed to fetch record for IDs: {id_str}\")\n",
    "            continue  # Skip this batch and proceed to the next\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            continue\n",
    "        finally:\n",
    "            try:\n",
    "                handle.close()\n",
    "            except:\n",
    "                pass  # Handle cases where handle might not be open\n",
    "\n",
    "        # Decode the record if necessary\n",
    "        if isinstance(batch_record, bytes):\n",
    "            try:\n",
    "                batch_record = batch_record.decode(\"utf-8\")\n",
    "            except Exception as e:\n",
    "                print(f\"Decoding error: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Truncate long values in the record\n",
    "        batch_record = truncate_values(batch_record, max_length=1000)\n",
    "\n",
    "        # convert to XML to JSON\n",
    "        batch_record = json.dumps(xmltodict.parse(batch_record), indent=2)\n",
    "\n",
    "        # Check for errors in the response\n",
    "        if \"Error occurred: cannot get document summary\" in batch_record:\n",
    "            print(f\"Failed to fetch record for IDs: {id_str}. Try a different database.\")\n",
    "            continue\n",
    "\n",
    "        records.append(batch_record)\n",
    "\n",
    "    # Combine all records into a single string\n",
    "    combined_records = \"\\n\".join(records)\n",
    "\n",
    "    return combined_records\n",
    "\n",
    "# records = efetch.invoke({ \"entrez_ids\" : [\"35966237\"], \"database\" : \"sra\"})\n",
    "# pprint(records)\n",
    "# records = efetch.invoke({\"entrez_ids\" : [\"200254051\"], \"database\" : \"gds\"})\n",
    "# pprint(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### esummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def esummary(\n",
    "    entrez_ids: Annotated[List[str], \"List of Entrez IDs\"],\n",
    "    database: Annotated[str, \"Database name (e.g., sra, gds, or pubmed)\"],\n",
    ") -> Annotated[str, \"eSummary results in XML format\"]:\n",
    "    \"\"\"\n",
    "    Run an Entrez esummary query on Entrez IDs to obtain summary information for the records.\n",
    "    Useful for obtaining summary information for specific records.\n",
    "    \"\"\"\n",
    "    batch_size = 200  # Maximum number of IDs per request as per NCBI guidelines\n",
    "    max_string_length = 500  # Maximum length of a string in the record\n",
    "    records = []\n",
    "    \n",
    "    for id_batch in batch_ids(entrez_ids, batch_size):\n",
    "        time.sleep(0.34)  # Respect NCBI's rate limits (no more than 3 requests per second)\n",
    "        id_str = \",\".join(id_batch)\n",
    "        \n",
    "        try:\n",
    "            # Fetch summary record for the current batch\n",
    "            handle = Entrez.esummary(db=database, id=id_str, retmode=\"xml\")\n",
    "            batch_record = handle.read()\n",
    "            handle.close()\n",
    "        except Entrez.Parser.ValidationError:\n",
    "            print(f\"Failed to fetch summary for IDs: {id_str}. Check if the IDs exist.\")\n",
    "            continue \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            continue\n",
    "        finally:\n",
    "            try:\n",
    "                handle.close()\n",
    "            except:\n",
    "                pass  # Handle cases where the handle might not be open\n",
    "        \n",
    "        # Decode the record if necessary\n",
    "        if isinstance(batch_record, bytes):\n",
    "            try:\n",
    "                batch_record = batch_record.decode(\"utf-8\")\n",
    "            except Exception as e:\n",
    "                print(f\"Decoding error: {e}\")\n",
    "                continue\n",
    "            \n",
    "        # Truncate long values in the record\n",
    "        batch_record = truncate_values(batch_record, max_length=500)\n",
    "\n",
    "        # convert to XML to JSON\n",
    "        batch_record = json.dumps(xmltodict.parse(batch_record), indent=2)\n",
    "\n",
    "        # Check for errors in the response\n",
    "        if \"ERROR\" in batch_record.upper() or \"INVALID_ID\" in batch_record.upper():\n",
    "            print(f\"Failed to fetch summary for IDs: {id_str}. Try a different database or verify the IDs.\")\n",
    "            continue\n",
    "\n",
    "        # Append the batch record to the list of records\n",
    "        records.append(batch_record)\n",
    "    \n",
    "    # Combine all batch records into a single string\n",
    "    combined_records = \"\\n\".join(records)\n",
    "    return combined_records\n",
    "\n",
    "# esummary.invoke({\"entrez_ids\" : [\"35966237\"], \"database\" : \"sra\"})\n",
    "# esummary.invoke({\"entrez_ids\" : [\"200121737\"], \"database\" : \"sra\"})\n",
    "# esummary.invoke({\"entrez_ids\" : [\"6697288\"], \"database\" : \"sra\"})\n",
    "# IDs = [\"200148729\", \"100024676\", \"100020301\", \"100018573\", \"305022831\", \"305022830\", \"305022829\", \"305022828\", \"305022827\", \"305022826\"]\n",
    "# esummary.invoke({\"entrez_ids\" : IDs, \"database\" : \"gds\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### elink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def elink(\n",
    "    entrez_ids: Annotated[List[str], \"List of Entrez IDs\"],\n",
    "    source_db: Annotated[str, \"Source database (e.g., 'sra')\"],\n",
    "    target_db: Annotated[str, \"Target database (e.g., 'bioproject', 'biosample', 'pubmed')\"],\n",
    ") -> Annotated[str, \"eLink results in XML format\"]:\n",
    "    \"\"\"\n",
    "    Find related entries between Entrez databases, particularly useful for finding\n",
    "    BioProject, BioSample, or publication records related to SRA entries.\n",
    "    \"\"\"\n",
    "    batch_size = 200  # Maximum number of IDs per request as per NCBI guidelines\n",
    "    records = []\n",
    "\n",
    "    for id_batch in batch_ids(entrez_ids, batch_size):\n",
    "        time.sleep(0.34)  # Respect NCBI's rate limits (no more than 3 requests per second)\n",
    "        id_str = \",\".join(id_batch)\n",
    "        \n",
    "        try:\n",
    "            handle = Entrez.elink(\n",
    "                id=id_str,\n",
    "                dbfrom=source_db,\n",
    "                db=target_db,\n",
    "                retmode=\"xml\"\n",
    "            )\n",
    "            batch_record = handle.read()\n",
    "            handle.close()\n",
    "        except Entrez.Parser.ValidationError:\n",
    "            batch_record = f\"Failed to find links for IDs: {id_str}\"\n",
    "        except Exception as e:\n",
    "            batch_record = f\"An error occurred: {e}\"\n",
    "        finally:\n",
    "            try:\n",
    "                handle.close()\n",
    "            except:\n",
    "                pass  # Handle cases where the handle might not be open\n",
    "        \n",
    "        # Decode the record if necessary\n",
    "        if isinstance(batch_record, bytes):\n",
    "            try:\n",
    "                batch_record = batch_record.decode(\"utf-8\")\n",
    "            except Exception as e:\n",
    "                print(f\"Decoding error: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Truncate long values in the record\n",
    "        batch_record = truncate_values(batch_record, max_length=1000)\n",
    "\n",
    "        # convert to XML to JSON\n",
    "        batch_record = json.dumps(xmltodict.parse(batch_record), indent=2)\n",
    "\n",
    "        # Check for errors in the response\n",
    "        if \"ERROR\" in batch_record.upper():\n",
    "            batch_record = f\"Failed to find links for IDs: {id_str}. Verify database names ({source_db}, {target_db}) and Entrez IDs.\"\n",
    "\n",
    "        # Append the batch record to the list of records\n",
    "        records.append(batch_record)\n",
    "    \n",
    "    # Combine all batch records into a single string\n",
    "    return \"\\n\".join(records)\n",
    "\n",
    "# elink.invoke({\"entrez_ids\" : [\"35966237\", \"200254051\"], \"source_db\" : \"gds\", \"target_db\" : \"pubmed\"})\n",
    "# elink.invoke({\"entrez_ids\" : ['200121737', '100024679', '303444964', '303444963', '303444962'], \"source_db\" : \"gds\", \"target_db\" : \"sra\"})\n",
    "# elink.invoke({\"entrez_ids\" : [\"200148729X\"], \"source_db\" : \"gds\", \"target_db\" : \"sra\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### which entrez database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def which_entrez_databases(\n",
    "    entrez_ids: Annotated[List[str], \"List of Entrez IDs\"],\n",
    ") -> Annotated[str, \"List of databases where each Entrez ID is found.\"]:\n",
    "    \"\"\"\n",
    "    Check which databases an Entrez ID is found in.\n",
    "    \"\"\"\n",
    "    databases = [\"sra\", \"gds\", \"pubmed\", \"biosample\", \"bioproject\"]\n",
    "    found_in = {entrez_id: [] for entrez_id in entrez_ids}\n",
    "\n",
    "    for db in databases:\n",
    "        for id_batch in batch_ids(entrez_ids, 200):\n",
    "            time.sleep(0.34)  # Respect the rate limit\n",
    "            try:\n",
    "                handle = Entrez.esummary(db=db, id=\",\".join(id_batch))\n",
    "                records = Entrez.read(handle)\n",
    "                handle.close()\n",
    "                # Extract the IDs that were successfully retrieved\n",
    "                if isinstance(records, list):\n",
    "                    found_ids = {record['Id'] for record in records}\n",
    "                else:\n",
    "                    # In case only one record is returned\n",
    "                    found_ids = {records['Id']}\n",
    "                for entrez_id in found_ids:\n",
    "                    found_in[entrez_id].append(db)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "    # Prepare the output\n",
    "    output_lines = []\n",
    "    for entrez_id in entrez_ids:\n",
    "        if not found_in[entrez_id]:\n",
    "            output_lines.append(f\"Entrez ID {entrez_id} not found in any databases.\")\n",
    "        else:\n",
    "            output_lines.append(f\"Entrez ID {entrez_id} found in: {', '.join(found_in[entrez_id])}.\")\n",
    "\n",
    "    return \"\\n\".join(output_lines)\n",
    "\n",
    "# Example usage\n",
    "# which_entrez_databases.invoke({\"entrez_ids\" : ['200121737', '100024679', '303444964']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fastq-dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import tempfile\n",
    "from subprocess import Popen, PIPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmd(cmd: list) -> Tuple[int, str, str]:\n",
    "    \"\"\"\n",
    "    Run sub-command and return returncode, output, and error.\n",
    "    Args:\n",
    "        cmd: Command to run\n",
    "    Returns:\n",
    "        tuple: (returncode, output, error)\n",
    "    \"\"\"\n",
    "    cmd = [str(i) for i in cmd]\n",
    "    p = Popen(cmd, stdout=PIPE, stderr=PIPE)\n",
    "    output, err = p.communicate()\n",
    "    return p.returncode, output, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def fastq_dump(\n",
    "    SRR_accessions: Annotated[List[str], \"List of SRA run accessions (e.g., SRR1234567)\"],\n",
    "    tries: Annotated[int, \"Number of attempts to run fastq-dump\"]=3\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Use fastq-dump to download the first few lines from the fastq files of the given SRR accession.\n",
    "    The tool is useful for quickly checking the fastq files of an SRR accession.\n",
    "    \"\"\"\n",
    "    # check if accession is valid\n",
    "    incorrect_accessions = [x for x in SRR_accessions if not x.startswith(\"SRR\")]\n",
    "    if len(incorrect_accessions) > 0:\n",
    "        acc_str = \", \".join(incorrect_accessions)\n",
    "        return f\"Invalid SRA accession numbers {acc_str}. Please provide >=1 valid SRR accession number.\"\n",
    "\n",
    "    # create temp directory\n",
    "    temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "    # create command\n",
    "    cmd = [\"fastq-dump\", \"--outdir\", temp_dir.name, \"--split-files\", \"--maxSpotId\", 2] + SRR_accessions\n",
    "\n",
    "    # run command\n",
    "    for i in range(tries):\n",
    "        return_code, output, error = run_cmd(cmd)\n",
    "        if return_code == 0:\n",
    "            break\n",
    "        time.sleep(5 * (i + 1))\n",
    "    if return_code != 0:\n",
    "        return f\"Error running fastq-dump: {error.decode('utf-8')}\"\n",
    "\n",
    "    # read in the files\n",
    "    files = os.listdir(temp_dir.name)\n",
    "    if len(files) == 0:\n",
    "        return \"No FASTQ files found.\"\n",
    "    fastq_data = \"\"\n",
    "    for file in files:\n",
    "        file_name = os.path.basename(file)\n",
    "        with open(os.path.join(temp_dir.name, file), \"r\") as f:\n",
    "            fastq_data += f\"#-- File: {file_name} --#\\n\"\n",
    "            fastq_data += f.read() + \"\\n\"\n",
    "            #fastq_data[file_name] = f.read()\n",
    "\n",
    "    # delete the temp directory\n",
    "    temp_dir.cleanup()\n",
    "    return str(fastq_data)\n",
    "    \n",
    "# accesssions = [\"SRR13112659\", \"SRR13112660\"]\n",
    "# accessions = [\"SRX4967529\"]\n",
    "#print(fastq_dump.invoke({\"SRR_accessions\" : accessions}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def sra_stat(\n",
    "    accessions: Annotated[List[str], \"List of GEO and/or SRA accessions (e.g., SRP359840, SRR1234567, or GSE12345)\"],\n",
    "    tries: Annotated[int, \"Number of attempts to run sra-stat\"]=3\n",
    "    ) -> str: \n",
    "    \"\"\"\n",
    "    Run the sra-stat CLI command (SRA Tools) on a GEO or SRA accession.\n",
    "    Use this tool to get information about all sequence data associated with the accession.\n",
    "    \"\"\"\n",
    "    # check if accession is valid\n",
    "    incorrect_accessions = [x for x in accessions if not x.startswith((\"SRP\", \"SRX\", \"SRR\", \"GSE\", \"GSM\"))]\n",
    "    if len(incorrect_accessions) > 0:\n",
    "        acc_str = \", \".join(incorrect_accessions)\n",
    "        return f\"Invalid GEO/SRA accession numbers {acc_str}. Please provide >=1 valid GEO and/or SRA accession.\"\n",
    "\n",
    "    # run sra-stat\n",
    "    cmd = ['sra-stat', '--xml', '--quick'] + accessions\n",
    "\n",
    "    # run command\n",
    "    for i in range(tries):\n",
    "        return_code, output, error = run_cmd(cmd)\n",
    "        if return_code == 0:\n",
    "            break\n",
    "        time.sleep(5 * (i + 1))\n",
    "    if return_code != 0:\n",
    "        return f\"Error running fastq-dump: {error.decode('utf-8')}\"\n",
    "        \n",
    "    # Decode the record if necessary\n",
    "    if isinstance(output, bytes):\n",
    "        try:\n",
    "            output = output.decode(\"utf-8\")\n",
    "        except Exception as e:\n",
    "            return f\"Decoding error: {e}\"\n",
    "            \n",
    "\n",
    "    # Truncate long values in the record\n",
    "    output = truncate_values(output, max_length=1000)\n",
    "\n",
    "    # convert to XML to JSON\n",
    "    output = json.dumps(xmltodict.parse(output), indent=2)\n",
    "    return str(output)\n",
    "\n",
    "accessions = [\"SRP359840\", \"SRR13112659\", \"SRR13112660\"]\n",
    "accessions = [\"GSE207334\"]\n",
    "# print(sra_stat.invoke({\"accessions\" : accessions}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model\n",
    "model_supervisor = ChatOpenAI(model=\"gpt-4o\", temperature=0.1)\n",
    "model_worker = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## esearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "esearch_agent = create_react_agent(\n",
    "    model=model_worker,\n",
    "    tools=[esearch],\n",
    "    state_modifier=\"\\n\".join([\n",
    "        \"You are an expert in bioinformatics and you are working on a project to find information about a specific dataset.\",\n",
    "        \"Based on the task provided by your supervisor, use Entrez esearch to help complete the task.\",\n",
    "        \"Provide a concise summary of your findings; use lists when possible; do not include helpful wording.\",\n",
    "    ])\n",
    ")\n",
    "\n",
    "# inputs = {\"messages\": [(\"user\", \"Investigate GSE121737\")]}\n",
    "# esearch_agent.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def invoke_esearch_worker(\n",
    "    message: Annotated[str, \"Message to the worker\"],\n",
    ") -> Annotated[str, \"Response from the worker\"]:\n",
    "    \"\"\"\n",
    "    Invoke the esearch worker to perform a task.\n",
    "    \"\"\"\n",
    "    result = esearch_agent.invoke({\"messages\": [(\"user\", message)]})\n",
    "    # just return the response\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"esearch worker\")]\n",
    "    }\n",
    "\n",
    "#invoke_esearch_worker.invoke({\"message\" : \"Investigate GSE121737\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## esummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "esummary_agent = create_react_agent(\n",
    "    model=model_worker,\n",
    "    tools=[esummary, which_entrez_databases],\n",
    "    state_modifier=\"\\n\".join([\n",
    "        \"You are an expert in bioinformatics and you are working on a project to find information about a specific dataset.\",\n",
    "        \"Based on the task provided by your supervisor, use Entrez esummary to help complete the task.\",\n",
    "        \"You can use which_entrez_databases to determine which databases to use for esummary queries.\",\n",
    "        \"Provide a concise summary of your findings; use lists when possible; do not include helpful wording.\",\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def invoke_esummary_worker(\n",
    "    message: Annotated[str, \"Message to the worker. Be sure to provide Entrez IDs.\"],\n",
    ") -> Annotated[str, \"Response from the worker\"]:\n",
    "    \"\"\"\n",
    "    Invoke the esummary worker to perform a task.\n",
    "    \"\"\"\n",
    "    result = esummary_agent.invoke({\"messages\": [(\"user\", message)]})\n",
    "    # just return the final response\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"esummary worker\")]\n",
    "    }\n",
    "\n",
    "# invoke_esummary_worker.invoke({\"message\" : \"Investigate Entrez ID 35966237\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## efetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "efetch_agent = create_react_agent(\n",
    "    model=model_worker,\n",
    "    tools=[efetch, which_entrez_databases],\n",
    "    state_modifier=\"\\n\".join([\n",
    "        \"You are an expert in bioinformatics and you are working on a project to find information about a specific dataset.\",\n",
    "        \"Based on the task provided by your supervisor, use Entrez efetch to help complete the task.\",\n",
    "        \"You can use which_entrez_databases to determine which databases to use for efetch queries.\",\n",
    "        \"Provide a concise summary of your findings; use lists when possible; do not include helpful wording.\",\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def invoke_efetch_worker(\n",
    "    message: Annotated[str, \"Message to the worker. Be sure to provide Entrez IDs.\"],\n",
    ") -> Annotated[str, \"Response from the worker\"]:\n",
    "    \"\"\"\n",
    "    Invoke the efetch worker to perform a task.\n",
    "    \"\"\"\n",
    "    result = efetch_agent.invoke({\"messages\": [(\"user\", message)]})\n",
    "    # just return the final response\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"efetch worker\")]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## elink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "elink_agent = create_react_agent(\n",
    "    model=model_supervisor,\n",
    "    tools=[elink, which_entrez_databases],\n",
    "    state_modifier=\"\\n\".join([\n",
    "        \"You are an expert in bioinformatics and you are working on a project to find information about a specific dataset.\",\n",
    "        \"Based on the task provided by your supervisor, use Entrez elink to help complete the task.\",\n",
    "        \"elink is useful for finding related entries between Entrez databases.\",\n",
    "        \"Generally, you will want to use the which_entrez_databases tool to determine which databases to use for elink queries.\",\n",
    "        \"Note that elink results are composed of Entrez IDs and not accessions (e.g., SRA accessions).\",\n",
    "        \"Provide a concise summary of your findings; use lists when possible; do not include helpful wording.\",\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def invoke_elink_worker(\n",
    "    message: Annotated[str, \"Message to the worker. Be sure to provide Entrez IDs.\"],\n",
    ") -> Annotated[str, \"Response from the worker\"]:\n",
    "    \"\"\"\n",
    "    Invoke the efetch worker to perform a task.\n",
    "    \"\"\"\n",
    "    result = elink_agent.invoke({\"messages\": [(\"user\", message)]})\n",
    "    # just return the final response\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"elink worker\")]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_agent = create_react_agent(\n",
    "    model=model_worker,\n",
    "    tools=[sra_stat, fastq_dump],\n",
    "    state_modifier=\"\\n\".join([\n",
    "        \"You are an expert in bioinformatics and you are working on a project to find information about a specific dataset.\",\n",
    "        \"Based on the task provided by your supervisor, use sra-stat and fastq-dump to help complete the task.\",\n",
    "        \"You can investige the sequence data (fastq files) associated with GEO and/or SRA accessions.\",\n",
    "        \"sra-stat provides information about the sequence data associated with GEO and/or SRA accessions.\",\n",
    "        \"fastq-dump is useful for quickly checking the fastq files of SRR accessions.\",\n",
    "        \"If you are provided with Entrez IDs instead of GEO/SRA accessions, just state that you require GEO and/or SRA accessions.\",\n",
    "        \"Provide a concise summary of your findings; use lists when possible; do not include helpful wording.\",\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def invoke_fastq_worker(\n",
    "    message: Annotated[str, \"Message to the worker. Be sure to provide GEO and/or SRA accessions.\"],\n",
    ") -> Annotated[str, \"Response from the worker\"]:\n",
    "    \"\"\"\n",
    "    Invoke the fastq worker to perform a task.\n",
    "    \"\"\"\n",
    "    result = fastq_agent.invoke({\"messages\": [(\"user\", message)]})\n",
    "    # just return the final response\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"fastq worker\")]\n",
    "    }\n",
    "\n",
    "# invoke_fastq_worker.invoke({\"message\" : \"Is SRR13112659 Illumina paired-end 10X Genomics data?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "def create_step_summary_chain(model: str=\"gpt-4o-mini\", max_tokens: int=35):\n",
    "    \"\"\"\n",
    "    Create a chain of tools to summarize each step in a workflow.\n",
    "    \"\"\"\n",
    "    template = \"\\n\".join([\n",
    "        \"Concisely summarize the provided step in the langgraph workflow.\",\n",
    "        f\"The summary must be {max_tokens} tokens or less.\",\n",
    "        \"Do not use introductory words such as \\\"The workflow step involves\\\"\",\n",
    "        \"Write your output as plain text instead of markdown.\",\n",
    "        \"#-- The workflow step --#\",\n",
    "        \"{step}\"\n",
    "    ])\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"step\"],\n",
    "        template=template\n",
    "    )\n",
    "\n",
    "    # Initialize the language model\n",
    "    llm = ChatOpenAI(model_name=model, temperature=0, max_tokens=max_tokens)\n",
    "\n",
    "    # Create the LLM chain\n",
    "    return prompt | llm\n",
    "\n",
    "msg = {'tools': {'messages': [ToolMessage(content=\"{'messages': [HumanMessage(content='- **Entrez ID: 200121737**\\\\n  - **SRX Accessions**: Not directly available, but related SRA ID is **SRP167700**\\\\n  - **GSE Accession**: GSE121737\\\\n  - **Samples**:\\\\n    - GSM3444963\\\\n    - GSM3444962\\\\n    - GSM3444964\\\\n\\\\n- **Entrez ID: 100024679**\\\\n  - **SRX Accessions**: Not directly available\\\\n  - **GSE Accession**: GSE132325; GSE151535; GSE206234; GSE240796; GSE192477; GSE206238; GSE166916; GSE121737; GSE184948\\\\n\\\\n- **Entrez ID: 303444964**\\\\n  - **SRX Accessions**: **SRX4967529**\\\\n  - **GSM Accession**: GSM3444964\\\\n\\\\n- **Entrez ID: 303444963**\\\\n  - **SRX Accessions**: **SRX4967528**\\\\n  - **GSM Accession**: GSM3444963\\\\n\\\\n- **Entrez ID: 303444962**\\\\n  - **SRX Accessions**: **SRX4967527**\\\\n  - **GSM Accession**: GSM3444962', additional_kwargs={}, response_metadata={}, name='esummary worker')]}\", name='invoke_esummary_worker', id='dac6ce94-900b-4a87-a6f6-e48292ab1a83', tool_call_id='call_vPNZmoRFcXpgwmzxzEFdTMHj')]}}\n",
    "step_summary_chain = create_step_summary_chain()\n",
    "#step_summary_chain.invoke({\"step\": msg, \"max_tokens\": 25}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrez_agent = create_react_agent(\n",
    "    model=model_supervisor,\n",
    "    tools=[\n",
    "        invoke_esearch_worker, invoke_esummary_worker, invoke_efetch_worker, invoke_elink_worker, \n",
    "        which_entrez_databases, invoke_fastq_worker\n",
    "    ],\n",
    "    state_modifier=\"\\n\".join([\n",
    "        \"You are a helpful senior bioinformatician assisting a researcher with a task involving Entrez databases.\",\n",
    "        \"You have a team of workers who can perform specific tasks using Entrez tools.\",\n",
    "        \"Provide guidance to the workers to help them complete the task successfully.\",\n",
    "        \"\\n\",\n",
    "        \"Generally, start with eSearch to find Entrez records, then use eFetch to get detailed information.\",\n",
    "        \"Use eSummary to obtain summary information on an Entrez record.\",\n",
    "        \"Use eLink to navigate between databases to find related records (e.g., GEO to SRA).\",\n",
    "        \"Use the fastq worker to investigate the sequence data associated with GEO and/or SRA accessions.\",\n",
    "        \"Note: the fastq worker calls sra-stat and fastq-dump, which both require SRA (or GEO) accessions; do not provide Entrez IDs to the fastq worker.\",\n",
    "        \"\\n\",\n",
    "        \"Generally, you will want to specify the database(s) to search (e.g., sra, gds, or pubmed).\",\n",
    "        \"If there are dozens of records, batch the IDs and call the worker multiple times to avoid rate limits and token count limits.\",\n",
    "        \"Continue sending tasks to your workers until you successfully complete the task.\",\n",
    "        \"Be very concise; provide simple lists when possible; do not include unnecessary wording such as \\\"If you need further assistance\\\".\",\n",
    "        \"Write your output as plain text instead of markdown.\",\n",
    "        \"\\n\",\n",
    "        \"#-- Accession notes --#\",\n",
    "        \"SRA accesssion prefixes: SRX, SRP, SRR\",\n",
    "        \"ENA accession prefixes: ERX, PRJNA, DRX, E-MTAB\",\n",
    "        \"GEO accession prefixes: GSE, GSM, GPL\",\n",
    "        \"BioProject accession prefixes: PRJNA, PRJEB, PRJDB\",\n",
    "        \"BioSample accession prefixes: SAMN, SAME\",\n",
    "        \"#-- Database notes --#\",\n",
    "        \"Entrez databases: sra, gds, pubmed, biosample, bioproject\",\n",
    "        \"#-- Accession conversion workflows --#\",\n",
    "        \"GSE -> SRP -> SRX -> SRR\",\n",
    "        \"GSE -> GSM -> SRS -> SRX -> SRR\",\n",
    "        \"GSM -> SRS -> SRX -> SRR\",\n",
    "        \"PRJNA -> SRX -> SRR\",\n",
    "        \"SAMN -> SRX -> SRR\",\n",
    "        \"ERP -> SRP -> SRX -> SRR\",\n",
    "        \"#-- Example workflows --#\",\n",
    "        \"# Task: Convert GSE123456 to SRX, SRP, or SRR accessions\",\n",
    "        \"  1. esearch of GSE accession to obtain Entrez IDs\",\n",
    "        \"  2. esummary of the Entrez IDs to get the SRX accessions\"\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Requesting the number of spots and bases for the sample SRR13112659 using the invoke_fastq_worker function.\n",
      "Step 2: Total spots and bases are summarized, with a detailed breakdown of member contributions in terms of spots and bases.\n",
      "Step 3: Total spots for SRR13112659: 7,676,492; total bases: 898,149,564. Breakdown includes four members with specific spots and bases\n",
      "The number of spots and bases for SRR13112659 are as follows:\n",
      "\n",
      "- Total Spots: 7,676,492\n",
      "- Total Bases: 898,149,564\n",
      "\n",
      "### Member Breakdown:\n",
      "1. **GTCTCTCG**\n",
      "   - Spots: 2,026,746\n",
      "   - Bases: 237,129,282\n",
      "2. **AATCTCTC**\n",
      "   - Spots: 2,041,326\n",
      "   - Bases: 238,835,142\n",
      "3. **CGGAGGGA**\n",
      "   - Spots: 1,930,369\n",
      "   - Bases: 225,853,173\n",
      "4. **TCAGAAAT**\n",
      "   - Spots: 1,678,051\n",
      "   - Bases: 196,331,967\n"
     ]
    }
   ],
   "source": [
    "def invoke_entrez_agent(\n",
    "    inputs: dict,\n",
    "    step_summary_chain: Any,\n",
    "    config: dict = {\"max_concurrency\" : 8, \"recursion_limit\": 50}\n",
    "):\n",
    "    \"\"\"\n",
    "    Invoke the Entrez agent to perform a task.\n",
    "    \"\"\"\n",
    "    final_step = \"\"\n",
    "    for i,step in enumerate(entrez_agent.stream(inputs, config=config)):\n",
    "        final_step = step\n",
    "        msg = step_summary_chain.invoke({\"step\": step})\n",
    "        print(f\"Step {i+1}: {msg.content}\")\n",
    "    try:\n",
    "        print(final_step[\"agent\"][\"messages\"][-1].content)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", \"Convert GSE121737 to SRX accessions\")]}\n",
    "invoke_entrez_agent(inputs, step_summary_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"messages\": [(\"user\", \"What are the number of spots and bases for SRR13112659?\")]}\n",
    "invoke_entrez_agent(inputs, step_summary_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Search for GSE148729 in the GDS database to retrieve Entrez IDs using the invoke_esearch_worker function.\n",
      "Step 2: Entrez IDs for GSE148729 in the GDS database are listed, ranging from 200148729 to 304477929.\n",
      "Step 3: Summarizes multiple Entrez IDs using the 'invoke_esummary_worker' function to retrieve relevant information.\n",
      "Step 4: Gene expression profiling data for SARS-CoV-1/2 infections in human cell lines, detailing samples, platforms, and related resources.\n",
      "Step 5: Identified SRP accession for GSE148729 as SRP256479, providing relevant information in response to the query.\n",
      "The SRP accession related to GSE148729 is **SRP256479**.\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [(\"user\", \"Obtain any available SRP accessions for GSE148729\")]}\n",
    "invoke_entrez_agent(inputs, step_summary_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Search for GSE196830 in the GDS database to retrieve Entrez IDs using the invoke_esearch_worker function.\n",
      "Step 2: Entrez IDs for GSE196830 in the GDS database were retrieved, listing 100 unique identifiers.\n",
      "Step 3: Link multiple Entrez IDs from the GDS database to the PubMed database to retrieve related publications.\n",
      "Failed to find links for IDs: 305902681. Verify database names (gds, pubmed) and Entrez IDs.\n",
      "Failed to find links for IDs: 100028939. Verify database names (gds, pubmed) and Entrez IDs.\n",
      "Step 4: Related PubMed IDs were found for one Entrez ID, while no publications were identified for four other Entrez IDs from the GDS database.\n",
      "Step 5: Identified publications related to GSE196830, providing PubMed IDs for one Entrez ID and noting no publications for others.\n",
      "Publications related to GSE196830:\n",
      "\n",
      "- PubMed IDs for Entrez ID 200196830:\n",
      "  - 38622708\n",
      "  - 36823676\n",
      "  - 35389779\n",
      "\n",
      "No related publications were found for the other Entrez IDs.\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [(\"user\", \"Obtain any available publications for GSE196830\")]}\n",
    "invoke_entrez_agent(inputs, step_summary_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Link PubMed ID 38622708 to the GEO database to retrieve related GEO accessions.\n",
      "Step 2: Retrieve related GEO accessions for PubMed ID 38622708: 200196830, 200196829, 200196735.\n",
      "Step 3: Retrieve GEO accessions for specified Entrez IDs using the invoke_esummary_worker function.\n",
      "Step 4: Error due to exceeding maximum string length in a request, requiring correction of the input content.\n",
      "Step 5: Retrieve GEO accessions for three specified Entrez IDs using the invoke_esummary_worker function.\n",
      "Step 6: Summarizes multiple GEO datasets related to single-cell eQTL mapping, detailing sample information, publication dates, and FTP links for data access.\n",
      "Step 7: Identified GEO accessions related to PubMed ID 38622708, detailing titles, sample counts, and FTP links for three datasets.\n",
      "The GEO accessions related to PubMed ID 38622708 are:\n",
      "\n",
      "1. **GSE196830**\n",
      "   - Title: Single-cell eQTL mapping identifies cell type specific genetic control of autoimmune disease\n",
      "   - Samples: 1179 total samples\n",
      "   - FTP Link: ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE196nnn/GSE196830/\n",
      "\n",
      "2. **GSE196829**\n",
      "   - Title: Single-cell eQTL mapping identifies cell type specific genetic control of autoimmune disease [Genotype_data]\n",
      "   - Samples: 1104 total samples\n",
      "   - FTP Link: ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE196nnn/GSE196829/\n",
      "\n",
      "3. **GSE196735**\n",
      "   - Title: Single-cell eQTL mapping identifies cell type specific genetic control of autoimmune disease [scRNAseq_data]\n",
      "   - Samples: 75 total samples\n",
      "   - FTP Link: ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE196nnn/GSE196735/\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [(\"user\", \"Obtain any available GEO accessions for the pubmed ID 38622708\")]}\n",
    "invoke_entrez_agent(inputs, step_summary_chain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SRAgent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
